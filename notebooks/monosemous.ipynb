{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = '../output/monosemous.bin'\n",
    "nmslib_params = {'method': 'hnsw', 'space': 'cosinesimil'}\n",
    "model_path = '../output/model-h2048p512/lstm-wsd-gigaword-google'\n",
    "vocab_path = '../output/vocab.2018-05-10-7d764e7.pkl'\n",
    "mono_path = '../output/monosemous-context-embeddings.2018-05-27-5cd9bb6.npz'\n",
    "hdn_list_vocab = '../output/hdn-list-vocab.2018-05-18-f48a06c.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing NMSLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "monos = np.load(mono_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904288, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mono_words, mono_embs, mono_hdn_lists = monos['mono_words'], monos['mono_embs'], monos['mono_hdn_lists']\n",
    "mono_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "some_words, some_emds = resample(mono_words, mono_embs, replace=False, n_samples=10)\n",
    "some_emds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 s, sys: 1.67 s, total: 5.37 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "s = cosine_similarity(some_emds, mono_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying by sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from model import LSTMLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../output/model-h2048p512/lstm-wsd-gigaword-google\n"
     ]
    }
   ],
   "source": [
    "lm = LSTMLanguageModel(sess, model_path, vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'I study computer science'.split()\n",
    "target_index = 3\n",
    "embs = lm.get_embeddings_sentence(sess, sent, target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'science'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from evaluate.wn_utils import synsets_graph_info\n",
    "\n",
    "def get_hdns(lemma):\n",
    "    graph_info = synsets_graph_info(wn_instance=wn,\n",
    "                                wn_version='30',\n",
    "                                lemma=lemma,\n",
    "                                pos='n')\n",
    "    return {info['under_lcs']: synset\n",
    "            for synset, info in graph_info.items() \n",
    "            if info['under_lcs']}\n",
    "    \n",
    "hdn_list = list(get_hdns(sent[target_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(hdn_list_vocab, 'rb') as f:\n",
    "    hdn_list2id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_of_same_hdn_list = (mono_hdn_lists == hdn_list2id[hdn_list])\n",
    "len(cases_of_same_hdn_list.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "word2id = np.load(vocab_path)\n",
    "id2word = {i: w for w, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16256, 434195,  38315,  94648,  74175,   5926,  25121, 103031,\n",
       "        72460,  38315,  39247,  22974,  30083,  32603, 177796, 231428,\n",
       "        85757,  85968,  59113,  40817, 133936,  86803, 178378, 264997,\n",
       "        83053,  58708,  46880,  25483,  65293, 792661, 132156,  30083],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mono_words[cases_of_same_hdn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eng-30-05616246-n', 'eng-30-05809192-n')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2synset = {synset2identifier(s, '30'):s for s in wn.all_synsets('n')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability.n.02', 'content.n.05']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2synset[h].name() for h in hdn_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_words = [id2word[i] for i in mono_words[cases_of_same_hdn_list]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate.wn_utils import synset2identifier\n",
    "relevant_hdns = []\n",
    "for w in relevant_words:\n",
    "    hypernyms = [synset2identifier(s, '30') for s in wn.synsets(w, 'n')[0].hypernym_paths()[0]]\n",
    "    rel_hdn, = [h for h in hypernyms if h in hdn_list]\n",
    "    relevant_hdns.append(rel_hdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cosine_similarity([embs], mono_embs[cases_of_same_hdn_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07344373,  0.01642235,  0.11265934, -0.00393955,  0.03521454,\n",
       "        -0.06778327,  0.06247198, -0.00956155,  0.01389751, -0.07077594,\n",
       "         0.11973589,  0.11337093,  0.05293576,  0.04902532,  0.13012496,\n",
       "         0.00500624,  0.08833097,  0.02415848,  0.03868581,  0.01956294,\n",
       "        -0.05338352, -0.02618037,  0.03757791, -0.11224613, -0.04880265,\n",
       "        -0.04376756, -0.01514762, -0.07666067,  0.01267537,  0.00895502,\n",
       "        -0.0066125 , -0.07674665]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('griffin', 'eng-30-05616246-n', -0.112246126),\n",
       " ('folklore', 'eng-30-05809192-n', -0.07674665),\n",
       " ('psychiatry', 'eng-30-05809192-n', -0.07666067),\n",
       " ('misconception', 'eng-30-05809192-n', -0.07077594),\n",
       " ('economics', 'eng-30-05809192-n', -0.06778327),\n",
       " ('razzmatazz', 'eng-30-05809192-n', -0.053383518),\n",
       " ('bioengineering', 'eng-30-05809192-n', -0.04880265),\n",
       " ('ergonomics', 'eng-30-05809192-n', -0.043767557),\n",
       " ('geriatrics', 'eng-30-05809192-n', -0.026180368),\n",
       " ('aptitude', 'eng-30-05616246-n', -0.015147625),\n",
       " ('doppelganger', 'eng-30-05616246-n', -0.009561549),\n",
       " ('technicolor', 'eng-30-05616246-n', -0.0066124965),\n",
       " ('endocrinology', 'eng-30-05809192-n', -0.0039395466),\n",
       " ('podiatry', 'eng-30-05809192-n', 0.005006239),\n",
       " ('onomastics', 'eng-30-05809192-n', 0.00895502),\n",
       " ('prosthetics', 'eng-30-05809192-n', 0.012675365),\n",
       " ('sorcery', 'eng-30-05809192-n', 0.013897514),\n",
       " ('counterplan', 'eng-30-05809192-n', 0.016422346),\n",
       " ('deity', 'eng-30-05809192-n', 0.019562941),\n",
       " ('antihero', 'eng-30-05616246-n', 0.024158482),\n",
       " ('amateurism', 'eng-30-05809192-n', 0.035214536),\n",
       " ('geochemistry', 'eng-30-05809192-n', 0.037577912),\n",
       " ('astrology', 'eng-30-05809192-n', 0.038685806),\n",
       " ('eyesight', 'eng-30-05616246-n', 0.04902532),\n",
       " ('folklore', 'eng-30-05809192-n', 0.052935757),\n",
       " ('vampire', 'eng-30-05809192-n', 0.06247198),\n",
       " ('ignorance', 'eng-30-05809192-n', 0.073443726),\n",
       " ('foretaste', 'eng-30-05809192-n', 0.08833097),\n",
       " ('misconception', 'eng-30-05809192-n', 0.112659335),\n",
       " ('goddess', 'eng-30-05809192-n', 0.11337093),\n",
       " ('geometry', 'eng-30-05809192-n', 0.11973589),\n",
       " ('philology', 'eng-30-05809192-n', 0.13012496)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(relevant_words, relevant_hdns, s[0]), key=lambda t: t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('science.n.01')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def disambiguate(sentence, target_index):\n",
    "    hdn2synset = get_hdns(sent[target_index])\n",
    "    hdn_list = tuple(sorted(hdn2synset))\n",
    "    cases_of_same_hdn_list = (mono_hdn_lists == hdn_list2id[hdn_list])\n",
    "    relevant_words = [id2word[i] for i in mono_words[cases_of_same_hdn_list]]\n",
    "    relevant_hdns = []\n",
    "    for w in relevant_words:\n",
    "        hypernyms = [synset2identifier(s, '30') for s in wn.synsets(w, 'n')[0].hypernym_paths()[0]]\n",
    "        rel_hdn, = [h for h in hypernyms if h in hdn2synset]\n",
    "        relevant_hdns.append(rel_hdn)\n",
    "    embs = lm.get_embeddings_sentence(sess, sent, target_index)\n",
    "    sims = cosine_similarity([embs], mono_embs[cases_of_same_hdn_list])[0]\n",
    "    hdn2score = defaultdict(float)\n",
    "    for hdn, sim in zip(relevant_hdns, sims):\n",
    "        if sim > 0:\n",
    "            hdn2score[hdn] += sim\n",
    "    return hdn2synset[max(hdn2score, key=lambda k: hdn2score[k])]\n",
    "\n",
    "id2synset[disambiguate('I study computer science'.split(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('computer.n.01')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2synset[disambiguate('I study computer science'.split(), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('costs.n.01')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2synset['eng-30-13293625-n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
