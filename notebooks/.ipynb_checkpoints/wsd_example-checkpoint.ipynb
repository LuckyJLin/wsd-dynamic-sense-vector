{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    'h100p10': {\n",
    "        'model_path': '../output/model-h100p10/lstm-wsd-gigaword-small_seed-124-best-model',\n",
    "        'vocab_path': '../output/model-h100p10/gigaword-for-lstm-wsd.index.pkl',\n",
    "    },\n",
    "    'h256p64': {\n",
    "        'model_path': '../output/model-h256p64/lstm-wsd-gigaword-h256p64-seed_12-best-model',\n",
    "        'vocab_path': '../output/model-h256p64/gigaword-for-lstm-wsd.index.pkl',\n",
    "    },\n",
    "    'h512p128': {\n",
    "        'model_path': '../output/model-h512p128/lstm-wsd-gigaword-large',\n",
    "        'vocab_path': '../output/model-h512p128/gigaword-lstm-wsd.index.pkl',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_to_use = 'h100p10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = model_configs[model_to_use]\n",
    "vocab = np.load(model_config['vocab_path'])\n",
    "target_id = vocab['<target>']\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10,513': 845353,\n",
       " '1:45pm': 725076,\n",
       " '872.81': 671940,\n",
       " 'Megabytes': 347426,\n",
       " 'P-54': 700694}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "sample_tokens = random.sample(vocab.keys(), 5)\n",
    "{t: vocab[t] for t in sample_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluate.tensor_utils' from '/Users/cumeo/Projects/spinoza/ulm-4/wsd-dynamic-sense-vector/evaluate/tensor_utils.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from evaluate import tensor_utils as utils\n",
    "utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../output/model-h100p10/lstm-wsd-gigaword-small_seed-124-best-model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Model_1/x:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph(model_config['model_path'] + '.meta', clear_devices=True)\n",
    "saver.restore(sess, model_config['model_path'])\n",
    "x, predicted_context_embs, lens = utils.load_tensors(sess)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.65137   -8.425376   2.446373   2.6197727  6.7266607 -4.5725756\n",
      "   1.8124135  2.7888153  1.8754734  6.959039 ]]\n",
      "[[-9.369549  -3.0150557 -4.1500454  3.7344537  4.160496  -2.5933745\n",
      "   6.343987   5.5194774  2.3988874  6.2405457]]\n",
      "[[-9.0635805 -1.3791523 -6.462949   3.994534   3.7958844  1.5434003\n",
      "   9.72546    6.61067    2.7794766  5.639398 ]]\n",
      "[[-5.0397134  -2.6272783  -4.667344    5.654272    0.90381366 10.726474\n",
      "  13.289057    7.207321    3.3882906   5.869152  ]]\n"
     ]
    }
   ],
   "source": [
    "sentence_tokens = 'I studied computer science'.lower().split()\n",
    "sentence_as_ids = [vocab.get(w) or vocab['<unkn>'] for w in sentence_tokens]\n",
    "for target_index in range(len(sentence_tokens)):\n",
    "    # possibly check if it is content word here\n",
    "    sentence_as_ids[target_index] = target_id\n",
    "    target_embeddings = sess.run(predicted_context_embs, {x: [sentence_as_ids],\n",
    "                                                              lens: [len(sentence_as_ids)]})\n",
    "    print(target_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
